{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db358429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23be092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(X, K, pMu, pSigma):\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    Px = np.zeros((N, K))\n",
    "    for i in range(K):\n",
    "        Xshift = X-np.tile(pMu[i], (N, 1))\n",
    "        lambda_flag = np.e**(-5)\n",
    "        conv = pSigma[i]+lambda_flag*np.eye(D)\n",
    "        inv_pSigma = np.linalg.inv(conv)\n",
    "        tmp = np.sum(np.dot(Xshift, inv_pSigma)*Xshift, axis=1)\n",
    "        coef = (2*np.pi)**(-D/2)*np.sqrt(np.linalg.det(inv_pSigma))\n",
    "        Px[:, i] = coef*np.e**(-1/2*tmp)\n",
    "    return Px\n",
    "\n",
    "def gmm(X, K):       \n",
    "    threshold = np.e**(-15)\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    pMu = centroids\n",
    "    pPi = np.zeros((1, K))\n",
    "    pSigma = np.zeros((K, D, D))\n",
    "    dist = np.tile(np.sum(X*X, axis=1).reshape(N,1), (1, K))+np.tile(np.sum(pMu*pMu, axis=1), (N, 1))-2*np.dot(X, pMu.T)\n",
    "    labels = np.argmin(dist,axis=1)\n",
    "    for i in range(K):\n",
    "        index = labels == i\n",
    "        Xk = X[index,:]\n",
    "        pPi[:,i] = (Xk.shape[0])/N\n",
    "        pSigma[i] = np.cov(Xk.T)\n",
    "    Loss = -float(\"inf\")\n",
    "    while True:\n",
    "        Px = calc_prob(X, K, pMu, pSigma)\n",
    "        pGamma = Px*np.tile(pPi, (N, 1))\n",
    "        pGamma = pGamma/np.tile(np.sum(pGamma, axis=1).reshape(N,1), (1, K))\n",
    "        Nk = np.sum(pGamma, axis=0)\n",
    "        pMu = np.dot(np.dot(np.diag(1/Nk), pGamma.T), X)\n",
    "        pPi = Nk/N\n",
    "        for i in range(K):\n",
    "            Xshift = X-np.tile(pMu[i], (N, 1))\n",
    "            pSigma[i] = np.dot(Xshift.T, np.dot(np.diag(pGamma[:, i]), Xshift))/Nk[i]\n",
    "        L = np.sum(np.log(np.dot(Px, pPi.T)), axis=0)\n",
    "        if L-Loss < threshold:\n",
    "            break\n",
    "        Loss = L\n",
    "    return Px,pMu,pSigma,pPi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1caedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":        \n",
    "    data = pd.read_csv('E:/pythonjupyter/03 COVID-19&air pollution/data/ft_data/wuhan_2018-2020_1.csv', encoding = \"gbk\")\n",
    "    data = pd.DataFrame(data)\n",
    "    data.iloc[:,2:] = data.iloc[:,2:].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) \n",
    "    tar_domain = data.iloc[6016:,:]\n",
    "    tar_domain_ori = tar_domain.iloc[:,3:]\n",
    "    Data_tar = tar_domain_ori.values\n",
    "    N = Data_tar.shape[0]\n",
    "    K = 5\n",
    "    rndp = random.sample(np.arange(N).tolist(),K)\n",
    "    centroids = Data_tar[rndp,:]\n",
    "    Px_tar,pMu_tar,pSigma_tar,pPi_tar = gmm(Data_tar, 5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12481260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(source):\n",
    "    temp1 = []\n",
    "    for i in range(0, 5):\n",
    "        temp = source[source['cluster'] == i].iloc[:,2:25] * pPi_tar[i]\n",
    "        temp1.append(temp)\n",
    "    temp2 = pd.concat([temp1[0], temp1[1], temp1[2], temp1[3], temp1[4]])\n",
    "    source = pd.concat([source.iloc[:,:2],temp2],axis = 1)\n",
    "    return source\n",
    "\n",
    "tar_domain = tar_domain.reset_index()\n",
    "tar_domain = tar_domain.iloc[:,1:]\n",
    "\n",
    "cluster_tar = pd.DataFrame(Px_tar)\n",
    "cluster_tar['cluster'] = cluster_tar.idxmax(1)\n",
    "tar_domain['cluster'] = cluster_tar['cluster']\n",
    "tar_domain = target_function(tar_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4020add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_function(source):\n",
    "    temp1 = []\n",
    "    for i in range(0, 5):\n",
    "        temp = source[source['cluster'] == i].iloc[:,2:25] * pPi[i]\n",
    "        temp1.append(temp)\n",
    "    temp2 = pd.concat([temp1[0], temp1[1], temp1[2], temp1[3], temp1[4]])\n",
    "    source = pd.concat([source.iloc[:,:2],temp2],axis = 1)\n",
    "    return source\n",
    "\n",
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])    \n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    L2_distance = ((total0-total1)**2).sum(2)\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)\n",
    " \n",
    "def mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n = int(source.size()[0])\n",
    "    m = int(target.size()[0])\n",
    "    kernels = guassian_kernel(source, target,kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    XX = kernels[:n, :n] \n",
    "    YY = kernels[n:, n:]\n",
    "    XY = kernels[:n, n:]\n",
    "    YX = kernels[n:, :n]\n",
    "    XX = torch.div(XX, n * n).sum(dim=1).view(1,-1)  \n",
    "    XY = torch.div(XY, -n * m).sum(dim=1).view(1,-1) \n",
    "    YX = torch.div(YX, -m * n).sum(dim=1).view(1,-1) \n",
    "    YY = torch.div(YY, m * m).sum(dim=1).view(1,-1)  \n",
    "    loss = (XX + XY).sum() + (YX + YY).sum()\n",
    "    return loss\n",
    "\n",
    "def min_mmd (pPi, sign=1.0):\n",
    "    return loss\n",
    "\n",
    "def func_deriv(pPi, sign=1):\n",
    "    jac_x0 = sign * (2 * pPi[0])\n",
    "    jac_x1 = sign * (2 * pPi[1])\n",
    "    jac_x2 = sign * (2 * pPi[2])\n",
    "    jac_x3 = sign * (2 * pPi[3])\n",
    "    jac_x4 = sign * (2 * pPi[4])\n",
    "    return np.array([jac_x0, jac_x1, jac_x2, jac_x3, jac_x4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a793f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    src_domain = data.head(6016)\n",
    "    data_1_ori = src_domain.iloc[:,3:]\n",
    "    Data = data_1_ori.values\n",
    "    N = Data.shape[0]\n",
    "    D = Data.shape[1]\n",
    "    K = 5\n",
    "    loss_array1 = []\n",
    "    src_domain = data.head(6016)\n",
    "    data_1_ori = src_domain.iloc[:,3:] \n",
    "    Data = data_1_ori.values\n",
    "    Px,pMu,pSigma,pPi = gmm(Data, 5) \n",
    "    cluster_1 = pd.DataFrame(Px)\n",
    "    cluster_1['cluster'] = cluster_1.idxmax(1)\n",
    "    src_domain['cluster'] = cluster_1['cluster']\n",
    "    src_domain = source_function(src_domain)\n",
    "    src_domain_1 = src_domain.iloc[:,3:] \n",
    "    tar_domain_1 = tar_domain.iloc[:,3:] \n",
    "    data_1 = torch.from_numpy(src_domain_1.values)\n",
    "    data_2 = torch.from_numpy(tar_domain_1.values)\n",
    "    loss = mmd(data_1,data_2)\n",
    "    cons = ({'type': 'eq','fun': lambda x: np.array([x[0] + x[1] + x[2] + x[3] + x[4] - 1]),\n",
    "                 'jac': lambda x: np.array([1, 1, 1, 1, 1])})\n",
    "    bnds = ((0, 1), (0, 1),(0, 1),(0, 1),(0, 1))\n",
    "    x0 = np.array([0.0, 1.0, 0.0, 0.0, 0.0])\n",
    "    res = minimize(min_mmd, x0, bounds=bnds,constraints=cons)  \n",
    "    loss_array = loss.numpy()\n",
    "    loss_array1.append(loss_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd5a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
